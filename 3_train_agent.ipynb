{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, recogym\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "pd.options.mode.chained_assignment = None \n",
    "# from inspect import getsource\n",
    "from recogym.evaluate_agent_sale import verify_agents_sale, plot_verify_agents_sale, plot_CR_CTR\n",
    "from tqdm import tqdm\n",
    "\n",
    "# env_1_sale_args is a dictionary of default parameters (i.e. number of products)\n",
    "from recogym import env_1_sale_args, Configuration\n",
    "from recogym.envs.utils_sale import (share_states, share_sale, env_infos, count_sales_first_session, \n",
    "                                     get_beta_confidence_interval, share_user_with_sale, share_clicks_with_sale)\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_sale_args['random_seed'] = 42\n",
    "\n",
    "# Initialize the gym for the first time by calling .make() and .init_gym()\n",
    "env = gym.make('reco-gym-sale-v1')\n",
    "env.init_gym(env_1_sale_args)\n",
    "\n",
    "# .reset() env before each episode (one episode per user).\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "env_1_sale_args['num_products'] = 10\n",
    "num_products = env_1_sale_args['num_products']\n",
    "\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_sale_args['random_seed'] = 42\n",
    "\n",
    "# Initialize the gym \n",
    "env = gym.make('reco-gym-sale-v1')\n",
    "env.init_gym(env_1_sale_args)\n",
    "\n",
    "env_1_sale_args['number_of_flips'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clicks\n",
    "from recogym.agents.sale_agent import ClickRewardProvider\n",
    "Click_rewards = ClickRewardProvider()\n",
    "\n",
    "## MDP\n",
    "from recogym.agents.sale_agent import MDPRewardProvider\n",
    "MDP_rewards = MDPRewardProvider()\n",
    "MDP_rewards_all = MDPRewardProvider(clicks_only=False)\n",
    "MDP_rewards_pureorganic = MDPRewardProvider(clicks_only=False, organic_only=True)\n",
    "\n",
    "rewards = {'click':Click_rewards,\n",
    "          'MDP':MDP_rewards,\n",
    "          'MDP_all':MDP_rewards_all,\n",
    "          'MDP_pureorganic':MDP_rewards_pureorganic}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recogym.agents.sale_agent import CountViewsClicksFeatureProvider, CountViewsFeatureProvider, ShareViewsClicksFeatureProvider, ShareViewsFeatureProvider\n",
    "vc_feature = CountViewsClicksFeatureProvider(env.config)\n",
    "v_feature = CountViewsFeatureProvider(env.config)\n",
    "vc_share_feature = ShareViewsClicksFeatureProvider(env.config)\n",
    "v_share_feature = ShareViewsFeatureProvider(env.config)\n",
    "\n",
    "features = {'vc':vc_feature,\n",
    "           'v':v_feature,\n",
    "           'vc_share':vc_share_feature,\n",
    "           'v_share':v_share_feature}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of users for training and AB test\n",
    "env_1_sale_args['num_users'] = 1000\n",
    "env_1_sale_args['num_users_AB'] = 5000\n",
    "num_users = env_1_sale_args['num_users']\n",
    "num_users_AB = env_1_sale_args['num_users_AB']\n",
    "\n",
    "# Choose features\n",
    "feature_name = 'v_share'\n",
    "feature = features[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recogym.agents.sale_agent import build_train_data\n",
    "from recogym.agents.sale_agent import SaleLikelihoodAgent, SaleProductLikelihoodAgent\n",
    "\n",
    "agents={}\n",
    "logs={}\n",
    "\n",
    "############## Random agent\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "random_agent = RandomAgent(Configuration(random_args))\n",
    "name_agent = 'rand'\n",
    "agents[name_agent] = random_agent\n",
    "try:\n",
    "    data = pkl.load(open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'rb'))\n",
    "except :\n",
    "    data = deepcopy(env).generate_logs(num_users)\n",
    "    pkl.dump(data,open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'wb'))\n",
    "logs[name_agent] = data\n",
    "    \n",
    "############## Organic agent\n",
    "from recogym.agents import OrganicUserEventCounterAgent, organic_user_count_args\n",
    "organic_counter_agent = OrganicUserEventCounterAgent(Configuration({**organic_user_count_args,\n",
    "                                                                    **env_1_sale_args,\n",
    "                                                                    'select_randomly': True}))\n",
    "name_agent = 'organic'\n",
    "agents[name_agent] = organic_counter_agent\n",
    "try:\n",
    "    data = pkl.load(open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'rb'))\n",
    "except :\n",
    "    data = deepcopy(env).generate_logs(num_users,agent=organic_counter_agent)\n",
    "    pkl.dump(data,open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'wb'))\n",
    "logs[name_agent] = data\n",
    "    \n",
    "############## Likelihood click\n",
    "name_agent = \"likclick\"\n",
    "try :\n",
    "    data = pkl.load(open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'rb'))\n",
    "except:\n",
    "    likelihood_logreg_click = SaleLikelihoodAgent(feature, Click_rewards)\n",
    "    likelihood_logreg_click.train(data)\n",
    "    agents[name_agent] = likelihood_logreg_click\n",
    "    data = deepcopy(env).generate_logs(num_users, agent=likelihood_logreg_click)\n",
    "    pkl.dump(data,open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'wb'))\n",
    "logs[name_agent] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random logging policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agents(name_logging,logs,feature_name,features):\n",
    "    info = {}\n",
    "    save_agents = {}\n",
    "    data = logs[name_logging]\n",
    "    feature = features[feature_name]\n",
    "    \n",
    "    # click agent\n",
    "    likelihood_logreg_click = SaleLikelihoodAgent(feature, Click_rewards)\n",
    "    likelihood_logreg_click.train(data)\n",
    "    info[likelihood_logreg_click.info[\"Name\"]] = likelihood_logreg_click.info\n",
    "    save_agents[\"likelihood_logreg_click\"] = likelihood_logreg_click\n",
    "    \n",
    "    # No discount\n",
    "    likelihood_saleclickprod = SaleProductLikelihoodAgent(feature_provider_list=[feature,feature], \n",
    "                                                    reward_provider_list=[Click_rewards,MDP_rewards_all], \n",
    "                                                    discounts=[0,0],discounts_with_action=False)\n",
    "    likelihood_saleclickprod.train(data)\n",
    "    info[likelihood_saleclickprod.info[\"Name\"]] = likelihood_saleclickprod.info\n",
    "    save_agents[\"likelihood_saleclickprod\"] = likelihood_saleclickprod\n",
    "\n",
    "    # non-specific discount, all observations\n",
    "    likelihood_saleclickprod_discount_all = SaleProductLikelihoodAgent(feature_provider_list=[feature,feature,feature], \n",
    "                                                    reward_provider_list=[Click_rewards,MDP_rewards_all,MDP_rewards_pureorganic], \n",
    "                                                    discounts=[0,0,-1],discounts_with_action=False)\n",
    "    likelihood_saleclickprod_discount_all.train(data)\n",
    "    info[likelihood_saleclickprod_discount_all.info[\"Name\"]] = likelihood_saleclickprod_discount_all.info\n",
    "    save_agents[\"likelihood_saleclickprod_discount_all\"] = likelihood_saleclickprod_discount_all\n",
    "    \n",
    "    # non-specific discount, clicked observations\n",
    "    likelihood_saleclickprod_discount = SaleProductLikelihoodAgent(feature_provider_list=[feature,feature,feature], \n",
    "                                                    reward_provider_list=[Click_rewards,MDP_rewards,MDP_rewards_pureorganic], \n",
    "                                                    discounts=[0,0,-1],discounts_with_action=False)\n",
    "    likelihood_saleclickprod_discount.train(data)\n",
    "    info[likelihood_saleclickprod_discount.info[\"Name\"]] = likelihood_saleclickprod_discount.info\n",
    "    save_agents[\"likelihood_saleclickprod_discount\"] = likelihood_saleclickprod_discount\n",
    "    \n",
    "    # Per product discount, all observations\n",
    "    likelihood_saleclickprod_discount_spe_all = SaleProductLikelihoodAgent(feature_provider_list=[feature,feature,feature], \n",
    "                                                    reward_provider_list=[Click_rewards,MDP_rewards_all,MDP_rewards_pureorganic], \n",
    "                                                    discounts=[0,0,-1],discounts_with_action=False)\n",
    "    likelihood_saleclickprod_discount_spe_all.train(data)\n",
    "    info[likelihood_saleclickprod_discount_spe_all.info[\"Name\"]] = likelihood_saleclickprod_discount_spe_all.info\n",
    "    save_agents[\"likelihood_saleclickprod_discount_spe_all\"] = likelihood_saleclickprod_discount_spe_all\n",
    "    \n",
    "    # Per product discount, clicked observations\n",
    "    likelihood_saleclickprod_discount_spe = SaleProductLikelihoodAgent(feature_provider_list=[feature,feature,feature], \n",
    "                                                    reward_provider_list=[Click_rewards,MDP_rewards,MDP_rewards_pureorganic], \n",
    "                                                    discounts=[0,0,-1],discounts_with_action=False)\n",
    "    likelihood_saleclickprod_discount_spe.train(data)\n",
    "    info[likelihood_saleclickprod_discount_spe.info[\"Name\"]] = likelihood_saleclickprod_discount_spe.info\n",
    "    save_agents[\"likelihood_saleclickprod_discount_spe\"] = likelihood_saleclickprod_discount_spe\n",
    "    \n",
    "    pkl.dump([info,save_agents],open(str('data/agents'+str(num_users)+name_logging+feature_name+'.pkl'),'wb'))\n",
    "    return info, save_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organic Users: 0it [00:00, ?it/s]\n",
      "Users:  18%|████████████▎                                                         | 883/5000 [26:05<4:42:07,  4.11s/it]"
     ]
    }
   ],
   "source": [
    "name_logging = 'rand'\n",
    "data = logs[name_logging]\n",
    "try :\n",
    "    info, save_agents = pkl.load(open(str('data/agents'+str(num_users)+name_logging+feature_name+'.pkl'),'rb'))\n",
    "except :\n",
    "    info, save_agents = train_agents(name_logging,logs,feature_name,features)\n",
    "\n",
    "# A/B test\n",
    "env.reset()\n",
    "res=verify_agents_sale(\n",
    "    env,\n",
    "    number_of_users=num_users_AB,\n",
    "    agents=save_agents\n",
    ")\n",
    "\n",
    "# save result\n",
    "pkl.dump([res, env_1_sale_args, info, save_agents],\n",
    "         open(\"data/res_\"+name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name+\".pkl\",\"wb\"))\n",
    "res_dict[name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name] = res\n",
    "\n",
    "# plot result\n",
    "plot_verify_agents_sale(res[\"sale rate\"], res[\"CTR\"], res[\"Tot sales\"], \n",
    "                        res['Share user with sale'], res['Share sale after click'],\n",
    "                       res[\"User embeddings\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_logging = 'organic'\n",
    "data = logs[name_logging]\n",
    "try :\n",
    "    info, save_agents = pkl.load(open(str('data/agents'+str(num_users)+name_logging+feature_name+'.pkl'),'rb'))\n",
    "except :\n",
    "    info, save_agents = train_agents(name_logging,logs,feature_name,features)\n",
    "\n",
    "# A/B test\n",
    "env.reset()\n",
    "res=verify_agents_sale(\n",
    "    env,\n",
    "    number_of_users=num_users_AB,\n",
    "    agents=save_agents\n",
    ")\n",
    "\n",
    "# save result\n",
    "pkl.dump([res, env_1_sale_args, info, save_agents],\n",
    "         open(\"data/res_\"+name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name+\".pkl\",\"wb\"))\n",
    "res_dict[name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name] = res\n",
    "\n",
    "# plot result\n",
    "plot_verify_agents_sale(res[\"sale rate\"], res[\"CTR\"], res[\"Tot sales\"], \n",
    "                        res['Share user with sale'], res['Share sale after click'],\n",
    "                       res[\"User embeddings\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_logging = 'likclick'\n",
    "data = logs[name_logging]\n",
    "try :\n",
    "    info, save_agents = pkl.load(open(str('data/agents'+str(num_users)+name_logging+feature_name+'.pkl'),'rb'))\n",
    "except :\n",
    "    info, save_agents = train_agents(name_logging,logs,feature_name,features)\n",
    "\n",
    "# A/B test\n",
    "env.reset()\n",
    "res=verify_agents_sale(\n",
    "    env,\n",
    "    number_of_users=num_users_AB,\n",
    "    agents=save_agents\n",
    ")\n",
    "\n",
    "# save result\n",
    "pkl.dump([res, env_1_sale_args, info, save_agents],\n",
    "         open(\"data/res_\"+name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name+\".pkl\",\"wb\"))\n",
    "res_dict[name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name] = res\n",
    "\n",
    "# plot result\n",
    "plot_verify_agents_sale(res[\"sale rate\"], res[\"CTR\"], res[\"Tot sales\"], \n",
    "                        res['Share user with sale'], res['Share sale after click'],\n",
    "                       res[\"User embeddings\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(res_dict,\n",
    "         open(\"data/res_dict\"+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name+\"_\"+str(len(res_dict)+\".pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
