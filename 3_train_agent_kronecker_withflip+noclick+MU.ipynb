{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we only need to normalize when there is some bandit events. For pure organic, it doesn't really make sense since we consider each row independently != if we look at a log where a row is a reco then we need to divide by the length of the organic session, which is stochastic (independent of our reco)\n",
    "\n",
    "actually we need this because otherwise when we apply the discount it won't work. At least we need it for the MDP reward\n",
    "--> for the organic user : we should divide by the number of time each action a is viewed by user u ?\n",
    "\n",
    "Idea : click => \"only one chance to click\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.966042202395077\n",
      "mu sale [-0.99379029 -3.12128904 -3.9968082  -0.13101334  1.12695637  0.82779815\n",
      " -4.48369477 -2.89367933 -0.97225191  0.96059318]\n",
      "mu sale [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import gym, recogym\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "pd.options.mode.chained_assignment = None \n",
    "# from inspect import getsource\n",
    "from recogym.evaluate_agent_sale import verify_agents_sale, plot_verify_agents_sale, plot_CR_CTR\n",
    "from tqdm import tqdm\n",
    "\n",
    "# env_1_sale_args is a dictionary of default parameters (i.e. number of products)\n",
    "from recogym import env_1_sale_args, Configuration\n",
    "from recogym.envs.utils_sale import (share_states, share_sale, env_infos, count_sales_first_session, \n",
    "                                     get_beta_confidence_interval, share_user_with_sale, share_clicks_with_sale)\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_sale_args['random_seed'] = 42\n",
    "\n",
    "# Initialize the gym for the first time by calling .make() and .init_gym()\n",
    "env = gym.make('reco-gym-sale-v1')\n",
    "env.init_gym(env_1_sale_args)\n",
    "\n",
    "# .reset() env before each episode (one episode per user).\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "env_1_sale_args['num_products'] = 10\n",
    "env_1_sale_args['number_of_flips'] = 5\n",
    "# env_1_sale_args['num_products'] = 100\n",
    "# env_1_sale_args['number_of_flips'] = 50\n",
    "\n",
    "num_products = env_1_sale_args['num_products']\n",
    "\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_sale_args['random_seed'] = 42\n",
    "env_1_sale_args['mu_sale'] = True \n",
    "env_1_sale_args['sigma_mu_sale'] = env_1_sale_args['sigma_mu_organic']/4\n",
    "\n",
    "\n",
    "# Initialize the gym \n",
    "env = gym.make('reco-gym-sale-v1')\n",
    "env.init_gym(env_1_sale_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flips 10\n"
     ]
    }
   ],
   "source": [
    "print('Number of flips',env_1_sale_args['number_of_flips'])\n",
    "nb_flips = env_1_sale_args['number_of_flips']\n",
    "mu_sale = env_1_sale_args['mu_sale']\n",
    "print(\"With mu sale = \",mu_sale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clicks\n",
    "from recogym.agents.sale_agent import ClickRewardProvider\n",
    "Click_rewards = ClickRewardProvider()\n",
    "\n",
    "## MDP\n",
    "from recogym.agents.sale_agent import MDPRewardProvider, PostDisplayRewardProvider,DifferenceRewardProvider,NoclickRewardProdivder\n",
    "# doesn't take into account the length of the observation\n",
    "MDP_rewards = MDPRewardProvider()\n",
    "MDP_rewards_all = MDPRewardProvider(clicks_only=False)\n",
    "# take into account length of the observation\n",
    "MDP_rewards_time = MDPRewardProvider(clicks_only=True, organic_only=False, normalize = True)\n",
    "MDP_rewards_all_time = MDPRewardProvider(clicks_only=False, organic_only=False, normalize = True)\n",
    "MDP_rewards_pureorganic = MDPRewardProvider(clicks_only=False, organic_only=True)\n",
    "PostDisplay_rewards = PostDisplayRewardProvider()\n",
    "Noclick_rewards_provider = NoclickRewardProdivder()\n",
    "Noclick_rewards_provider_time = NoclickRewardProdivder(normalize = True)\n",
    "# Diff_rewards = DifferenceRewardProvider(MDP_rewards_all_time,MDP_rewards_pureorganic,normalize = False)\n",
    "# Diff_rewards_norm = DifferenceRewardProvider(MDP_rewards_all_time,MDP_rewards_pureorganic,normalize = True)\n",
    "\n",
    "rewards = {'click':Click_rewards,\n",
    "          'MDP':MDP_rewards,\n",
    "          'MDP_all':MDP_rewards_all,\n",
    "          'MDP_time':MDP_rewards_time,\n",
    "          'MDP_all_time':MDP_rewards_all_time,\n",
    "          'MDP_pureorganic':MDP_rewards_pureorganic,\n",
    "          'PostDisplay':PostDisplay_rewards}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recogym.agents.sale_agent import CountViewsClicksFeatureProvider, CountViewsFeatureProvider, ShareViewsClicksFeatureProvider, ShareViewsFeatureProvider\n",
    "vc_feature = CountViewsClicksFeatureProvider(env.config)\n",
    "v_feature = CountViewsFeatureProvider(env.config)\n",
    "vc_share_feature = ShareViewsClicksFeatureProvider(env.config)\n",
    "v_share_feature = ShareViewsFeatureProvider(env.config)\n",
    "\n",
    "features = {'vc':vc_feature,\n",
    "           'v':v_feature,\n",
    "           'vc_share':vc_share_feature,\n",
    "           'v_share':v_share_feature}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of users for training and AB test\n",
    "env_1_sale_args['num_users'] = 5000\n",
    "env_1_sale_args['num_users_AB'] = 1000\n",
    "num_users = env_1_sale_args['num_users']\n",
    "num_users_AB = env_1_sale_args['num_users_AB']\n",
    "\n",
    "# Choose features\n",
    "feature_name = 'v_share'\n",
    "feature = features[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organic Users: 0it [00:00, ?it/s]\n",
      "Users: 100%|███████████████████████████████████████████████████████████████████████| 5000/5000 [02:47<00:00, 29.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from recogym.agents.sale_agent import build_train_data\n",
    "from recogym.agents.sale_agent import SaleLikelihoodAgent, SaleProductLikelihoodAgent\n",
    "from recogym.agents.sale_agent import train_agents, train_timeagents\n",
    "\n",
    "agents={}\n",
    "logs={}\n",
    "\n",
    "############## Random agent\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "random_agent = RandomAgent(Configuration(random_args))\n",
    "\n",
    "if mu_sale == True:\n",
    "    name_agent = 'rand'+str(nb_flips)+\"MU\"\n",
    "else:\n",
    "    name_agent = 'rand'+str(nb_flips)\n",
    "    \n",
    "agents[name_agent] = random_agent\n",
    "try:\n",
    "    data = pkl.load(open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'rb'))\n",
    "except :\n",
    "    data = deepcopy(env).generate_logs(num_users)\n",
    "    pkl.dump(data,open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'wb'))\n",
    "logs[name_agent] = data\n",
    "\n",
    "############## Random agent\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "random_agent = RandomAgent(Configuration(random_args))\n",
    "name_agent = 'rand'+str(nb_flips)\n",
    "agents[name_agent] = random_agent\n",
    "try:\n",
    "    data = pkl.load(open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'rb'))\n",
    "except :\n",
    "    data = deepcopy(env).generate_logs(num_users)\n",
    "    pkl.dump(data,open(str('data\\data'+str(num_users)+name_agent+'.pkl'),'wb'))\n",
    "logs[name_agent] = data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents with no notion of time (needed or neglected) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all models, no weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_extension = 'kron'+str(nb_flips)\n",
    "res_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kronecker features\n",
      "Click agent\n",
      "Post display agent\n",
      "No discount\n"
     ]
    }
   ],
   "source": [
    "if mu_sale == True:\n",
    "    name_logging = 'rand'+str(nb_flips)+\"MU\"\n",
    "else:\n",
    "    name_logging = 'rand'+str(nb_flips)\n",
    "    \n",
    "data = logs[name_logging]\n",
    "try :\n",
    "    info, save_agents = pkl.load(open(str('data/agents'+str(num_users)+name_logging+feature_name+name_extension+'.pkl'),'rb'))\n",
    "except :\n",
    "    info, save_agents = train_agents(name_logging,logs,feature_name,features, num_users=num_users, \n",
    "                                     kronecker_features=True,additional_models_only=False)\n",
    "\n",
    "# A/B test\n",
    "env.reset()\n",
    "res=verify_agents_sale(\n",
    "    env,\n",
    "    number_of_users=num_users_AB,\n",
    "    agents={\n",
    "        **agents, \n",
    "        **save_agents},\n",
    "    name = name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name+name_extension\n",
    ")\n",
    "pkl.dump([res, env_1_sale_args, info, save_agents],\n",
    "         open(\"data/res_\"+name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name+name_extension+\".pkl\",\"wb\"))\n",
    "\n",
    "\n",
    "res_dict[name_logging+str(num_users)+\"_\"+str(num_users_AB)+\"_\"+feature_name+name_extension] = res\n",
    "\n",
    "# plot result\n",
    "plot_verify_agents_sale(res[\"CTR\"], res[\"Tot sales ATT\"], res['Share user with sale ATT'], \n",
    "                        res[\"Tot sales\"], res['Share user with sale'])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(res[\"CTR\"])\n",
    "display(res[\"Tot sales ATT\"])\n",
    "display(res['Share user with sale ATT'])\n",
    "display(res[\"Tot sales\"])\n",
    "display(res['Share user with sale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump(res,open(\"data/clean/res_noweights_notime_10flips.pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
